"""
RAGFlow é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ RAGFlow æ„å»ºä¼ä¸šçº§ RAG åº”ç”¨
"""

import requests
import json
from typing import List, Dict, Any

# ============================================================================
# RAGFlow API å®¢æˆ·ç«¯
# ============================================================================

class RAGFlowClient:
    """RAGFlow API å®¢æˆ·ç«¯"""

    def __init__(self, base_url: str, api_key: str):
        """
        åˆå§‹åŒ– RAGFlow å®¢æˆ·ç«¯

        Args:
            base_url: RAGFlow æœåŠ¡å™¨åœ°å€ï¼Œå¦‚ "http://localhost:9380"
            api_key: API å¯†é’¥
        """
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    def create_dataset(self, name: str, description: str = "") -> Dict[str, Any]:
        """
        åˆ›å»ºæ•°æ®é›†

        Args:
            name: æ•°æ®é›†åç§°
            description: æ•°æ®é›†æè¿°

        Returns:
            åˆ›å»ºçš„æ•°æ®é›†ä¿¡æ¯
        """
        url = f"{self.base_url}/api/v1/dataset"
        payload = {
            "name": name,
            "description": description
        }

        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        return response.json()

    def upload_document(self, dataset_id: str, file_path: str) -> Dict[str, Any]:
        """
        ä¸Šä¼ æ–‡æ¡£åˆ°æ•°æ®é›†

        Args:
            dataset_id: æ•°æ®é›† ID
            file_path: æ–‡æ¡£è·¯å¾„

        Returns:
            ä¸Šä¼ ç»“æœ
        """
        url = f"{self.base_url}/api/v1/dataset/{dataset_id}/document"
        # æ³¨æ„ï¼šå®é™…å®ç°éœ€è¦å¤„ç†æ–‡ä»¶ä¸Šä¼ 
        print(f"ä¸Šä¼ æ–‡æ¡£: {file_path} åˆ°æ•°æ®é›†: {dataset_id}")
        return {"status": "success", "document_id": "doc_123"}

    def parse_document(self, dataset_id: str, document_id: str) -> Dict[str, Any]:
        """
        è§£ææ–‡æ¡£

        Args:
            dataset_id: æ•°æ®é›† ID
            document_id: æ–‡æ¡£ ID

        Returns:
            è§£æç»“æœ
        """
        url = f"{self.base_url}/api/v1/dataset/{dataset_id}/document/{document_id}/parse"
        payload = {
            "chunk_method": "manual",  # æˆ– "automatic"
            "chunk_method": {
                "chunk_token_count": 128,
                "chunk_overlap_rate": 0.2
            }
        }

        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        return response.json()

    def create_chat(self, dataset_ids: List[str], name: str) -> Dict[str, Any]:
        """
        åˆ›å»ºèŠå¤©ä¼šè¯

        Args:
            dataset_ids: å…³è”çš„æ•°æ®é›† ID åˆ—è¡¨
            name: èŠå¤©ä¼šè¯åç§°

        Returns:
            åˆ›å»ºçš„èŠå¤©ä¼šè¯ä¿¡æ¯
        """
        url = f"{self.base_url}/api/v1/chat"
        payload = {
            "name": name,
            "dataset_ids": dataset_ids,
            "llm": {
                "model_name": "gpt-3.5-turbo",
                "temperature": 0.1
            }
        }

        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        return response.json()

    def chat(self, chat_id: str, question: str, history: List[Dict] = None) -> Dict[str, Any]:
        """
        å‘é€èŠå¤©æ¶ˆæ¯

        Args:
            chat_id: èŠå¤©ä¼šè¯ ID
            question: é—®é¢˜
            history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰

        Returns:
            AI å›å¤
        """
        url = f"{self.base_url}/api/v1/chat/{chat_id}/question"
        payload = {
            "question": question,
            "history": history or []
        }

        response = requests.post(url, headers=self.headers, json=payload)
        response.raise_for_status()
        return response.json()


# ============================================================================
# ç¤ºä¾‹ 1: åŸºæœ¬çš„ RAGFlow ä½¿ç”¨æµç¨‹
# ============================================================================

def ragflow_basic_workflow():
    """RAGFlow åŸºæœ¬å·¥ä½œæµç¨‹ç¤ºä¾‹"""
    print("=" * 60)
    print("ç¤ºä¾‹ 1: RAGFlow åŸºæœ¬å·¥ä½œæµç¨‹")
    print("=" * 60)

    print("""
RAGFlow å·¥ä½œæµç¨‹ï¼š
1. åˆ›å»ºæ•°æ®é›† â†’ 2. ä¸Šä¼ æ–‡æ¡£ â†’ 3. è§£ææ–‡æ¡£ â†’ 4. åˆ›å»ºèŠå¤© â†’ 5. å¼€å§‹å¯¹è¯

ç¤ºä¾‹ä»£ç ï¼š

# 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
client = RAGFlowClient(
    base_url="http://localhost:9380",
    api_key="your-api-key"
)

# 2. åˆ›å»ºæ•°æ®é›†
dataset = client.create_dataset(
    name="æŠ€æœ¯æ–‡æ¡£åº“",
    description="å­˜å‚¨æŠ€æœ¯æ–‡æ¡£å’Œæ•™ç¨‹"
)
dataset_id = dataset["data"]["id"]

# 3. ä¸Šä¼ æ–‡æ¡£
client.upload_document(dataset_id, "docs/python-guide.txt")
client.upload_document(dataset_id, "docs/ml-intro.txt")

# 4. è§£ææ–‡æ¡£ï¼ˆå¯é€‰ï¼Œç­‰å¾…è§£æå®Œæˆï¼‰
client.parse_document(dataset_id, "doc_123")

# 5. åˆ›å»ºèŠå¤©ä¼šè¯
chat = client.create_chat(
    dataset_ids=[dataset_id],
    name="æŠ€æœ¯åŠ©æ‰‹"
)
chat_id = chat["data"]["id"]

# 6. å¼€å§‹å¯¹è¯
response = client.chat(chat_id, "Python æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ")
print(response["data"]["answer"])
    """)


# ============================================================================
# ç¤ºä¾‹ 2: æ‰¹é‡æ–‡æ¡£å¤„ç†
# ============================================================================

def batch_document_processing():
    """æ‰¹é‡æ–‡æ¡£å¤„ç†ç¤ºä¾‹"""
    print("=" * 60)
    print("ç¤ºä¾‹ 2: æ‰¹é‡æ–‡æ¡£å¤„ç†")
    print("=" * 60)

    print("""
æ‰¹é‡å¤„ç†æ–‡æ¡£çš„æœ€ä½³å®è·µï¼š

def process_documents(client, dataset_id, doc_paths):
    '''æ‰¹é‡å¤„ç†æ–‡æ¡£'''
    results = []

    for doc_path in doc_paths:
        try:
            # ä¸Šä¼ æ–‡æ¡£
            upload_result = client.upload_document(dataset_id, doc_path)
            doc_id = upload_result["document_id"]

            # è§£ææ–‡æ¡£
            parse_result = client.parse_document(dataset_id, doc_id)

            results.append({
                "document": doc_path,
                "status": "success",
                "chunks": parse_result["data"]["chunk_count"]
            })

            print(f"âœ“ å·²å¤„ç†: {doc_path}")

        except Exception as e:
            results.append({
                "document": doc_path,
                "status": "error",
                "error": str(e)
            })
            print(f"âœ— å¤„ç†å¤±è´¥: {doc_path}, é”™è¯¯: {e}")

    return results

# ä½¿ç”¨ç¤ºä¾‹ï¼š
doc_paths = [
    "docs/python-basics.txt",
    "docs/advanced-python.txt",
    "docs/ml-guide.txt"
]
results = process_documents(client, dataset_id, doc_paths)
    """)


# ============================================================================
# ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯
# ============================================================================

def multi_turn_conversation():
    """å¤šè½®å¯¹è¯ç¤ºä¾‹"""
    print("=" * 60)
    print("ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯")
    print("=" * 60)

    print("""
å®ç°å¤šè½®å¯¹è¯ï¼š

def chat_with_history(client, chat_id):
    '''å¸¦å†å²è®°å½•çš„å¤šè½®å¯¹è¯'''
    history = []

    while True:
        question = input("\\nè¯·è¾“å…¥é—®é¢˜ (è¾“å…¥ 'quit' é€€å‡º): ")

        if question.lower() == 'quit':
            break

        # å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
        response = client.chat(chat_id, question, history)

        # æ›´æ–°å†å²è®°å½•
        history.append({"question": question})
        history.append({"answer": response["data"]["answer"]})

        print(f"\\nğŸ¤– AI: {response['data']['answer']}")
        print(f"ğŸ“š æ¥æº: {response['data']['reference']}")

    return history

# å¼€å§‹å¤šè½®å¯¹è¯
chat_history = chat_with_history(client, chat_id)
    """)


# ============================================================================
# ç¤ºä¾‹ 4: LangChain + RAGFlow é›†æˆ
# ============================================================================

def langchain_ragflow_integration():
    """LangChain ä¸ RAGFlow é›†æˆç¤ºä¾‹"""
    print("=" * 60)
    print("ç¤ºä¾‹ 4: LangChain + RAGFlow é›†æˆ")
    print("=" * 60)

    print("""
ç»“åˆ LangChain çš„çµæ´»æ€§å’Œ RAGFlow çš„ä¼ä¸šçº§èƒ½åŠ›ï¼š

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

class HybridRAGSystem:
    '''æ··åˆ RAG ç³»ç»Ÿ'''

    def __init__(self, ragflow_client, llm):
        self.ragflow = ragflow_client
        self.llm = llm
        self.template = PromptTemplate(
            input_variables=["context", "question"],
            template='''åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æä¾›ä¸“ä¸šã€è¯¦ç»†çš„å›ç­”ã€‚'''
        )
        self.chain = LLMChain(llm=self.llm, prompt=self.template)

    def query(self, chat_id, question):
        # 1. ä» RAGFlow è·å–ä¸Šä¸‹æ–‡
        ragflow_response = self.ragflow.chat(chat_id, question)

        # 2. ä½¿ç”¨ LangChain ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        final_answer = self.chain.run(
            context=ragflow_response["data"]["answer"],
            question=question
        )

        return {
            "answer": final_answer,
            "sources": ragflow_response["data"]["reference"]
        }

# ä½¿ç”¨ç¤ºä¾‹ï¼š
hybrid_system = HybridRAGSystem(ragflow_client, llm)
result = hybrid_system.query(chat_id, "è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ")
    """)


# ============================================================================
# ç¤ºä¾‹ 5: å®é™…éƒ¨ç½²è€ƒè™‘
# ============================================================================

def deployment_considerations():
    """RAGFlow éƒ¨ç½²æ³¨æ„äº‹é¡¹"""
    print("=" * 60)
    print("ç¤ºä¾‹ 5: éƒ¨ç½²æ³¨æ„äº‹é¡¹")
    print("=" * 60)

    print("""
éƒ¨ç½² RAGFlow çš„æœ€ä½³å®è·µï¼š

1. Docker éƒ¨ç½²
   docker pull ragflow/ragflow:latest
   docker run -d -p 9380:9380 ragflow/ragflow

2. ç¯å¢ƒé…ç½®
   - å†…å­˜: å»ºè®® 8GB+
   - å­˜å‚¨: SSDï¼Œè¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å­˜å‚¨å‘é‡
   - GPU: å¯é€‰ï¼ŒåŠ é€ŸåµŒå…¥å’Œæ¨ç†

3. å®‰å…¨é…ç½®
   - ä½¿ç”¨ API Key è®¤è¯
   - é…ç½® HTTPS
   - é™åˆ¶è®¿é—® IP

4. æ€§èƒ½ä¼˜åŒ–
   - åˆç†è®¾ç½® chunk_size (128-512 tokens)
   - è°ƒæ•´ chunk_overlap (0.1-0.3)
   - ä½¿ç”¨å¼‚æ­¥å¤„ç†æ‰¹é‡æ–‡æ¡£

5. ç›‘æ§å’Œç»´æŠ¤
   - ç›‘æ§ API å“åº”æ—¶é—´
   - å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
   - å¤‡ä»½å‘é‡æ•°æ®åº“

6. æˆæœ¬æ§åˆ¶
   - è®¾ç½® token ä½¿ç”¨é™åˆ¶
   - å®æ–½ç¼“å­˜ç­–ç•¥
   - ä¼˜åŒ–æ£€ç´¢å‚æ•°ï¼ˆk å€¼ï¼‰
    """)


if __name__ == "__main__":
    print("\nğŸš€ RAGFlow é›†æˆç¤ºä¾‹\n")

    ragflow_basic_workflow()
    batch_document_processing()
    multi_turn_conversation()
    langchain_ragflow_integration()
    deployment_considerations()

    print("\n" + "=" * 60)
    print("ğŸ“¦ RAGFlow å®‰è£…å’Œå¯åŠ¨ï¼š")
    print("1. ä¸‹è½½ RAGFlow: https://ragflow.io/download")
    print("2. Docker éƒ¨ç½²: docker run -d -p 9380:9380 ragflow/ragflow")
    print("3. è®¿é—®æ§åˆ¶å°: http://localhost:9380")
    print("4. è·å– API Key")
    print("=" * 60)
    print("\nğŸ’¡ å­¦ä¹ å»ºè®®ï¼š")
    print("1. å…ˆç”¨ Docker éƒ¨ç½² RAGFlow ä½“éªŒ")
    print("2. é€šè¿‡ Web ç•Œé¢ç†Ÿæ‚‰åŠŸèƒ½")
    print("3. å†ä½¿ç”¨ API è¿›è¡Œå¼€å‘")
    print("4. å¯¹æ¯” LangChain å’Œ RAGFlow çš„é€‚ç”¨åœºæ™¯")
    print("=" * 60 + "\n")
